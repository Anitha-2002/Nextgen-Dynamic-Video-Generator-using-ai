# Nextgen-Dynamic-Video-Generator-using-ai
This AI tool helps you create captivating and informative AI-generated video tutorials on any topic! With a charming character featuring facial animation and informative slides, it can explain any topic with ease. The best part? You have full control over the tutorial's creativity, humor, level of explanation, character appearance, and voice. â¤ï¸âœ¨

Give it a try for free! ğŸ”¥ It leverages the powerful capabilities of various tools.
ğŸš€ Features

    ğŸ§  The script is generated using Cohere's language model. (You can obtain a trial API key for free!)
    ğŸ—£ï¸ Seamless integration with Edge TTS for high-quality voiceovers.
    ğŸ˜„ Engaging facial animation powered by SadTalker.
    ğŸ–¼ï¸ Eye-catching and relevant images from Google for slides.
    ğŸ¨ Customizable creativity, humor, explanation level, character appearance, and voice.

 How it works

âœ¨ It all starts with the creation of a script using the create_script function. ğŸ“œ This function takes various parameters such as topic, level of explanation, target audience age, creativity, and humor. ğŸ­ With these parameters in mind, the script is carefully crafted to explain the chosen topic. To accomplish this, we leverage the power of the Cohere API and Langchain. ğŸ¤

ğŸ™ï¸ Once the script is ready, we move on to the create_audio_image function. This function splits the script into smaller sentences, which are then used to generate audio dialogues using Microsoft's Edge Text-to-Speech (TTS) service. ğŸ—£ï¸ In parallel, we generate a search query for each sentence using Cohere and Langchain once again. These search queries help us retrieve relevant images from Google, which will be used as slides in the presentation. ğŸ–¼ï¸

ğŸ¥ With the audio files and character images in place, we proceed to create the videos using the Sadtalker library. ğŸ¬ First, we generate videos for the character animations, and then we transform the still images from Google into slide videos. ğŸï¸ These slide videos will be seamlessly integrated into the final video presentation. To add an element of randomness, we assign a random number to each video and slide pair. Based on this number, we position the slides and talking character either to the left or right, or even use the image as the background. The talking character may appear in the bottom left or right corner of the screen. ğŸ¯

ğŸ“¼ Finally, we save the completed video, combining the slide videos and character animation videos. The resulting video is now ready to be shared! ğŸ‰ To bring it all together, we rely on FastAPI for the backend, and for the frontend, we utilize Next.js and Tailwind CSS. ğŸš€
